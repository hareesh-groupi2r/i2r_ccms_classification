# CCMS Classification Project Structure

## ğŸ“ Clean Organized Structure

```
ccms_classification/
â”œâ”€â”€ ğŸ¯ backend/                    # CORE INTEGRATION FILES
â”‚   â”œâ”€â”€ api/                      # REST API endpoints
â”‚   â”œâ”€â”€ services/                 # Business logic (imports from ../classifier/)
â”‚   â”œâ”€â”€ requirements.txt          # Production dependencies
â”‚   â”œâ”€â”€ start_integrated_backend.sh
â”‚   â””â”€â”€ README.md                 # Integration guide
â”‚
â”œâ”€â”€ ğŸ”§ classifier/                # SHARED CLASSIFICATION MODULES
â”‚   â”œâ”€â”€ hybrid_rag.py            # Core classification algorithms
â”‚   â”œâ”€â”€ embeddings.py            # Vector operations
â”‚   â”œâ”€â”€ pdf_extractor.py         # PDF processing
â”‚   â””â”€â”€ ...                      # Other classification modules
â”‚
â”œâ”€â”€ ğŸ“š docs/                      # DOCUMENTATION
â”‚   â”œâ”€â”€ *.md                     # Technical documentation
â”‚   â””â”€â”€ REQUIREMENTS_GUIDE.md    # Dependency documentation
â”‚
â”œâ”€â”€ ğŸ§ª tests_standalone/          # DEVELOPMENT & TESTING
â”‚   â”œâ”€â”€ test_*.py                # Test files
â”‚   â”œâ”€â”€ debug_*.py               # Debug utilities
â”‚   â”œâ”€â”€ requirements_*.txt       # Development dependencies
â”‚   â””â”€â”€ original_tests/          # Original test structure
â”‚
â”œâ”€â”€ ğŸ”§ temp_tests/               # TEMPORARY UTILITIES
â”‚   â”œâ”€â”€ check_issue_types.py    # Utility scripts
â”‚   â”œâ”€â”€ lot21_batch_test.py     # Batch processing tests
â”‚   â”œâ”€â”€ process_*.sh            # Shell processing scripts
â”‚   â””â”€â”€ README.md               # Temp files documentation
â”‚
â”œâ”€â”€ ğŸ—ƒï¸ data/                     # DATA & EMBEDDINGS
â”‚   â”œâ”€â”€ embeddings/             # Vector embeddings
â”‚   â”œâ”€â”€ synthetic/              # Synthetic training data
â”‚   â””â”€â”€ backups/                # Data backups
â”‚
â”œâ”€â”€ âš™ï¸ CONFIG & DEPLOYMENT
â”‚   â”œâ”€â”€ config.yaml             # Main configuration
â”‚   â”œâ”€â”€ batch_config.yaml       # Batch processing config
â”‚   â”œâ”€â”€ Dockerfile              # Container configuration
â”‚   â”œâ”€â”€ docker-compose.yml      # Multi-container setup
â”‚   â”œâ”€â”€ service.sh              # Service management
â”‚   â””â”€â”€ start_integrated_backend.sh  # Main startup script
â”‚
â”œâ”€â”€ ğŸ“Š DATA FILES
â”‚   â”œâ”€â”€ *.xlsx                  # Mapping and analysis files
â”‚   â””â”€â”€ issue_category_mapping_diffs/  # Mapping analysis
â”‚
â””â”€â”€ ğŸ”— INTEGRATION
    â”œâ”€â”€ requirements.txt        # Points to backend/requirements.txt
    â”œâ”€â”€ integrated_backend/     # Current working backend
    â””â”€â”€ integrated_backend.backup/  # Backup of integrated backend
```

## ğŸ¯ For Integration Use

**Essential Directories:**
- `backend/` - API and service layer
- `classifier/` - Core classification algorithms
- `data/` - Embeddings and training data (optional, can regenerate)

**Optional:**
- `docs/` - Documentation reference
- `config.yaml` - Configuration customization

## ğŸ§ª For Development Use

**Development Directories:**
- `tests_standalone/` - Comprehensive testing utilities
- `temp_tests/` - Temporary scripts and batch processing
- `data/` - Training data and embeddings

## ğŸš€ Quick Commands

### Integration Setup
```bash
pip install -r requirements.txt    # Install dependencies
./start_integrated_backend.sh      # Start service
```

### Development Setup
```bash
pip install -r tests_standalone/requirements_*.txt  # Dev dependencies
python tests_standalone/test_*.py   # Run specific tests
```

### Service Management
```bash
./service.sh start    # Start service
./service.sh status   # Check status
./service.sh stop     # Stop service
```

## ğŸ“ Maintenance Notes

- **Keep** `backend/` lean and focused on integration
- **Use** `tests_standalone/` for all development activities
- **Document** new features in `docs/`
- **Archive** completed utilities from `temp_tests/`

This structure provides clear separation of concerns and makes it easy to identify exactly what's needed for different use cases.